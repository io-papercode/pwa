{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import erf,erfc\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from utils import *\n",
    "from pwa import PWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(opts,epoch,nr_samples):\n",
    "    #model\n",
    "    model = PWA(opts)\n",
    "    batch_size = opts['batch_size']\n",
    "    mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "    fmnist = input_data.read_data_sets('Fashion_MNIST_data',one_hot=True)\n",
    "    from tqdm import tqdm\n",
    "    #training loop\n",
    "    for ep in range(epoch):\n",
    "        for iter in tqdm(range(nr_samples // batch_size)):\n",
    "            #obtain a mini-batch\n",
    "            #tuple:images,labels\n",
    "            if opts['dataset'] == 'mnist':\n",
    "                #if opts['dataset'] == 'fmnist':\n",
    "                #    mnist = fmnist\n",
    "\n",
    "                batch = mnist.train.next_batch(batch_size)[0]\n",
    "                if opts['binarize']:\n",
    "                    batch = np.random.binomial(1,batch)\n",
    "                loss, mloss, rloss, kloss = model.run_single_step(batch,training=False)\n",
    "\n",
    "            elif opts['dataset'] == 'celeba':\n",
    "                loss, mloss, rloss, kloss = model.run_single_step(np.zeros(shape=(batch_size,784),dtype=float),training=False)\n",
    "\n",
    "            #train: execute forward and backward pass\n",
    "        print('[Epoch {}] Loss: {}, {}, {}'.format(ep,rloss,mloss,kloss))\n",
    "    print('Done!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(13)\n",
    "tf.set_random_seed(13)\n",
    "opts = {}\n",
    "opts['dataset'] = 'mnist' # 'fmnist', 'celeba'\n",
    "opts['lr_adam'] = 1e-3\n",
    "opts['lr_rsgd'] = 1e-3\n",
    "opts['batch_size'] = 64\n",
    "opts['beta_mmd'] = 1e3\n",
    "opts['beta_kld'] = 10.0\n",
    "opts['lambda_mmd'] = 1.0\n",
    "opts['mmd_kernel'] = 'laplacian'\n",
    "opts['varregnorm'] = 2 # L1 or L2\n",
    "opts['dim_z'] = 5\n",
    "opts['hyp_c'] = 1.0\n",
    "opts['mmd_q'] = 1\n",
    "opts['use_expmap'] = False\n",
    "opts['nw_size'] = 'large'\n",
    "opts['binarize'] = True\n",
    "opts['init_std'] = 0.01\n",
    "opts['init_bias'] = 0.0\n",
    "opts['conv_filters_dim'] = 5\n",
    "opts['num_filters'] = 1024\n",
    "opts['num_layers'] = 4\n",
    "\n",
    "print(opts)\n",
    "#nr_samples = mnist.train.num_examples\n",
    "model = trainer(opts, epoch=5, nr_samples=60000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction: left recon, right ground truth\n",
    "#z = np.random.normal(size=[model.batch_size,model.dim_z])\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "batch = mnist.test.next_batch(100)\n",
    "batch = batch[0]\n",
    "if opts['binarize']:\n",
    "    batch = np.random.binomial(1,batch)\n",
    "x_reconstructed, z = model.reconstruction(batch)\n",
    "#x_generated = model.generate(z)\n",
    "n = 10\n",
    "h = 28\n",
    "w = 28\n",
    "I_reconstructed = np.empty((h*n,2*w*n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        x = np.concatenate((x_reconstructed[i*n+j,:].reshape(h,w),batch[i*n+j,:].reshape(h,w)),axis=1)\n",
    "        I_reconstructed[i*h:(i+1)*h,j*2*w:(j+1)*2*w] = x\n",
    "plt.figure(figsize = (10,20))\n",
    "plt.imshow(I_reconstructed,cmap='gray')\n",
    "#plt.savefig('mnist_recon.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np_project_hyp_vec(np_sample_gauss_pd(shape=[model.batch_size, model.dim_z],oversample=20,radius=1.0,sigma=1.0),1.0)\n",
    "print(z.shape)\n",
    "\n",
    "x_generated = model.generate(z)\n",
    "h = 28\n",
    "w = 28\n",
    "# 10x10 grid\n",
    "n = np.sqrt(model.batch_size).astype(np.int32)\n",
    "I_generated = np.empty((h*n, w*n))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        I_generated[i*h:(i+1)*h, j*w:(j+1)*w] = x_generated[i*n+j, :].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(I_generated, cmap='gray_r')\n",
    "plt.savefig('mnist_5_h_100ep.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with 2d latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "opts_2d = {}\n",
    "opts_2d['dataset'] = 'mnist'\n",
    "opts_2d['lr_adam'] = 1e-3\n",
    "opts_2d['lr_rsgd'] = 1e-3\n",
    "opts_2d['batch_size'] = 100 \n",
    "opts_2d['beta_mmd'] = 1e2\n",
    "opts_2d['beta_kld'] = 10.0\n",
    "opts_2d['lambda_mmd'] = 1.0\n",
    "opts_2d['mmd_kernel'] = 'laplacian'\n",
    "opts_2d['varregnorm'] = 2 # L1 or L2\n",
    "opts_2d['dim_z'] = 2\n",
    "opts_2d['hyp_c'] = 1.0\n",
    "opts_2d['mmd_q'] = 1\n",
    "opts_2d['nw_size'] = 'large'\n",
    "opts_2d['use_expmap'] = False\n",
    "opts_2d['binarize'] = True\n",
    "\n",
    "model_2d = trainer(opts_2d,epoch=5, nr_samples=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model: transformation\n",
    "batch = mnist.test.next_batch(3000)\n",
    "z = model_2d.transformer(batch[0])\n",
    "\n",
    "#z_prior = np_sample_gauss_hp(shape=[model_2d.batch_size, model_2d.dim_z],oversample=20,radius=3.0,sigma=1.0)\n",
    "#z_prior = np_exp_map(1.0*np.random.randn(model_2d.batch_size, model_2d.dim_z).astype(np.float32),c=1.0)\n",
    "z_prior = np_sample_gauss_pd(shape=[model_2d.batch_size, model_2d.dim_z],oversample=20,radius=0.85,sigma=1.0)\n",
    "\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.scatter(z[:, 0], z[:, 1], c=np.argmax(batch[1], 1))\n",
    "plt.scatter(z_prior[:,0],z_prior[:,1],c='r')\n",
    "#plt.colorbar()\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 2d grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 40\n",
    "x = np.linspace(-1.0, 1.0, n)\n",
    "y = np.linspace(-1.0, 1.0, n)\n",
    "\n",
    "#r = np.logspace(0, 1, n)\n",
    "#y = np.linspace(0,2*pi,n)\n",
    "h = 28\n",
    "w = 28\n",
    "\n",
    "I_latent = np.empty((h*n, w*n))\n",
    "for i, yi in enumerate(x):\n",
    "    for j, xi in enumerate(y):\n",
    "        z = np.array([[xi, yi]]*model_2d.batch_size)\n",
    "        x_hat = model_2d.generate(z)\n",
    "        I_latent[(n-i-1)*28:(n-i)*28, j*28:(j+1)*28] = x_hat[20].reshape(28, 28)\n",
    "        \n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(I_latent, cmap=\"gray_r\")\n",
    "plt.savefig(\"mnist_disk_5ep.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
